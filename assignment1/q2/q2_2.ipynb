{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q2_ref import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_path = \"./data/b/w-100-40-4.csv\"\n",
    "b_path = \"./data/b/b-100-40-4.csv\"\n",
    "\n",
    "X_train = np.array([[-1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1]]).astype(np.float128)\n",
    "T_train = np.array([[0, 0, 0, 1]])\n",
    "layer_dims = [X_train.shape[1]]\n",
    "layer_dims.extend([100, 40])\n",
    "layer_dims.extend([T_train.shape[1]])\n",
    "layers = build_layers(layer_dims)\n",
    "\n",
    "weights = pd.read_csv(w_path, header=None).drop([0], axis=1)\n",
    "weights = weights.values\n",
    "biases = pd.read_csv(b_path, header=None).drop([0], axis=1)\n",
    "biases = biases.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights[14:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 100)\n",
      "(100,)\n",
      "[-0.63515496 -0.68102014 -1.50158572 -0.36892512 -0.35299936  0.12738439\n",
      "  0.51753134  0.74783683 -0.80937755 -0.6326859  -0.44665483 -0.68692023\n",
      "  0.20931008  0.48030823  0.1385172  -0.79010016 -0.38585034  0.55766618\n",
      "  0.3433474   0.06734387 -0.61580515 -0.91060323  2.17104316 -0.05055463\n",
      "  1.55235219  0.79615581 -0.54516947 -1.8707031  -0.56236541 -1.78359485\n",
      "  0.07063438 -0.4745371   0.25230587 -1.11092496 -0.08980446 -0.83654934\n",
      " -0.41440707  0.85330921  0.61422664 -0.23856676 -1.05528796  0.43343547\n",
      "  1.76411951  1.19764614 -0.94886827 -0.46865168 -1.26019132  1.58028519\n",
      " -0.55569267  0.64981532  0.83796829  1.8300091   0.26930639 -1.84875643\n",
      " -0.74980503 -0.26773301  0.63126999 -0.08714293 -0.06924902 -0.16782281\n",
      "  0.6494987   0.62043548  0.14440846  1.1600455  -1.05437219  0.26477793\n",
      " -0.67461497  1.32087278 -0.95990545 -0.80743057 -0.3282226   0.91708761\n",
      " -0.31676835  0.92281324 -0.89297682  1.93504393  0.91986132  1.06622767\n",
      " -1.94102836 -1.40802598  1.67250633  1.13577557  0.34432349 -0.64709413\n",
      " -1.02792585 -1.8707844   0.66110045 -1.80463302  1.16553581  0.66385794\n",
      "  0.15607753  0.41361356  1.21111631 -0.17612132  0.94243783  0.63343585\n",
      " -0.1138803   0.45799664 -0.61556059  0.38528553]\n",
      "(100, 40)\n",
      "(40,)\n",
      "[ 0.66545147  1.42655563  1.15807724 -0.49619114 -0.01035039  0.6172055\n",
      "  0.33629721 -0.35823798 -0.9950155  -1.43977821  0.36476439  0.27952403\n",
      " -0.35806641  0.01473876  2.00852013  0.61419076  1.49516761  0.05475781\n",
      " -0.78674197  0.45881724  0.11117996 -1.45264781  0.9403379  -0.67439246\n",
      "  0.08579944  0.56813127 -0.097896    1.10255766 -0.33832964 -0.90882677\n",
      "  0.79865068  0.01966669  2.02008724 -0.44655094 -0.22028461 -0.39466101\n",
      " -2.55315113 -0.30545026  1.63600707 -1.01111007]\n",
      "(40, 4)\n",
      "(4,)\n",
      "[1.50888944 2.03829694 0.94560856 1.19386733]\n",
      "Linear Layer: 14, 100\n",
      "Relu Layer\n",
      "Linear Layer: 100, 40\n",
      "Relu Layer\n",
      "Linear Layer: 40, 4\n",
      "Softmax Layer\n"
     ]
    }
   ],
   "source": [
    "for (idx, l) in enumerate(layers):\n",
    "    if idx % 2 == 0:\n",
    "        num_rows = layer_dims[idx//2]\n",
    "        weights_block = weights[:num_rows]\n",
    "        weights_usable = weights_block[:,~np.isnan(weights_block).all(0)]\n",
    "        print(weights_usable.shape)\n",
    "        layers[idx].W = weights_usable\n",
    "        weights = np.delete(weights, slice(0, num_rows), axis=0)\n",
    "        \n",
    "        biases_block = biases[0]\n",
    "        biases_usable = biases_block[:, ~np.isnan(biases_block).all(0)]\n",
    "        biases_usable = biases_usable[~np.isnan(biases_usable).all(1)].flatten()\n",
    "        print(biases_usable.shape)\n",
    "        print(biases_usable)\n",
    "        layers[idx].b = biases_usable\n",
    "        biases = np.delete(biases, 0, axis=0)\n",
    "\n",
    "for l in layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = forward_step(X_train, layers)\n",
    "param_grads = backward_step(activations, T_train, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
